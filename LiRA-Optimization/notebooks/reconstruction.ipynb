{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljl3y0qA1gmE"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def get_df(name):\n",
        "  url = f'https://raw.githubusercontent.com/iGEM-UGM/iGEM-UGM-drylab/main/{name}'\n",
        "  response = requests.get(url)\n",
        "  with open(name, 'wb') as f:\n",
        "      f.write(response.content)\n",
        "\n",
        "  return(pd.read_csv(name))\n",
        "\n",
        "def save_data(df, filepath):\n",
        "  df.to_csv(filepath, index=False)\n",
        "  # Download the file\n",
        "  files.download(filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF2NT8wr-2Fq"
      },
      "source": [
        "#1.0-kqs-gathering-sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jXawyevBBEH"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium\n",
        "\n",
        "# Install xvfb\n",
        "apt install -y xvfb\n",
        "\n",
        "# Install Selenium-Profiles\n",
        "pip uninstall -y selenium_profiles\n",
        "pip install --no-cache-dir selenium_profiles>=2.2.6\n",
        "\n",
        "# pip install https://github.com/kaliiiiiiiiii/Selenium-Profiles/archive/refs/heads/dev.zip # dev-branch\n",
        "\n",
        "# install python packages\n",
        "pip install google-colab-shell\n",
        "pip install webdriver-manager\n",
        "pip install Pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQOI1va-A7-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "def scrap_data_design(link, trial):\n",
        "  driver.get(f'{link}/{trial}')  # test client hints\n",
        "  # Add a time delay to allow for page loading\n",
        "  time.sleep(2)  # Adjust the delay as needed\n",
        "  # dropdown sequences\n",
        "  button = driver.find_elements(By.CSS_SELECTOR, \"div.title\")[1]\n",
        "  button.click()\n",
        "  showscreen(driver)\n",
        "\n",
        "  #scrap the table of result\n",
        "  tables = driver.find_elements(By.CLASS_NAME, \"ui.table\")\n",
        "  table_data = []\n",
        "  for tab in tables:\n",
        "    rows = tab.find_elements(By.TAG_NAME, \"tr\")\n",
        "    for row in rows:\n",
        "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
        "        row_data = [cell.text for cell in cells]\n",
        "        table_data.append(row_data)\n",
        "\n",
        "  df = pd.DataFrame(table_data, columns=[\"Domain_Strand\", \"Sequence\"])\n",
        "  return(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM8ziezXDFtT"
      },
      "outputs": [],
      "source": [
        "def get_design_data(link):\n",
        "  driver.get(link+'/0')\n",
        "  # Find the menu element by its class name\n",
        "  menu = driver.find_element(By.CLASS_NAME, \"dropdown.icon\")\n",
        "  # Click the menu element\n",
        "  menu.click()\n",
        "  menu = driver.find_element(By.CSS_SELECTOR, \"div.menu.transition.visible\")\n",
        "  # Find the items within the menu\n",
        "  items = menu.find_elements(By.CLASS_NAME, \"item\")\n",
        "\n",
        "  # Get the count of items\n",
        "  item_count = len(items)\n",
        "  print(\"Number of items:\", item_count)\n",
        "\n",
        "  # Create an empty DataFrame\n",
        "  datas = pd.DataFrame()\n",
        "\n",
        "  # Iterate over the items\n",
        "  for i in range(item_count):\n",
        "      # Scraping data using the scrap_data_design function\n",
        "      data = scrap_data_design(link, i)\n",
        "\n",
        "      n = len(data)  # The number of times to repeat the value\n",
        "      result = [i+1] * n\n",
        "      data['Trial'] = result\n",
        "      # Append data to the datas DataFrame\n",
        "      datas = datas.append(data, ignore_index=True)\n",
        "  return(datas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "qcNuVon2-gr8",
        "outputId": "b71333c0-f887-4903-e6c5-9d0a09efe27b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae4f05967b85>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmydriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Login\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.nupack.org'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Find the button by its CSS selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mydriver' is not defined"
          ]
        }
      ],
      "source": [
        "driver = mydriver.start()\n",
        "# Login\n",
        "driver.get('https://www.nupack.org')\n",
        "\n",
        "# Find the button by its CSS selector\n",
        "button = driver.find_element(By.CSS_SELECTOR, \"a.item[href='/auth/log-in']\")\n",
        "\n",
        "# Click the button\n",
        "button.click()\n",
        "\n",
        "# Find the input field by its class name\n",
        "input_field = driver.find_element(By.CLASS_NAME, \"ui input\")\n",
        "\n",
        "# Clear any existing text in the input field (optional)\n",
        "input_field.clear()\n",
        "\n",
        "# Enter the desired email address\n",
        "email_address = mail #add your email here\n",
        "input_field.send_keys(email_address)\n",
        "input_element = driver.find_element(By.CLASS_NAME, \"ui.fluid.icon.input\")\n",
        "\n",
        "# Find the input field within the parent element\n",
        "password_field = input_element.find_element(By.TAG_NAME, \"input\")\n",
        "password_field.send_keys(password) #add your password here\n",
        "\n",
        "eye_icon = driver.find_element(By.CSS_SELECTOR, \".eye.fitted.link.icon\")\n",
        "eye_icon.click()\n",
        "# Find the button\n",
        "button = driver.find_element(By.CLASS_NAME, \"ui.button.orange\")\n",
        "button.click()\n",
        "\n",
        "# start scrapping\n",
        "link = 'https://www.nupack.org/design/results/a10996f7-3a7c-49eb-ba3c-bf682effc883'\n",
        "\n",
        "output_sequence = get_design_data(link)\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()\n",
        "\n",
        "# save link into csv data downloaded automatically\n",
        "code = link.split('/')[-1]\n",
        "name = f\"table_data_{code}.csv\"\n",
        "save_data(output_sequence, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F47ZP6hpEwAV"
      },
      "source": [
        "# 2.0-kqs-parameter-gathering-nupack-analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30boRWreGrKP"
      },
      "outputs": [],
      "source": [
        "import nupack\n",
        "from nupack import *\n",
        "def get_rbs_index(c):\n",
        "    a = ''\n",
        "    for i in c.strands:\n",
        "        a += str(i)\n",
        "    rbs = \"UAGAGGAGAUG\"\n",
        "    index = a.find(rbs)\n",
        "    return(int(index))\n",
        "\n",
        "def calculate_gc_percentage(string):\n",
        "    gc_count = string.count(\"G\") + string.count(\"C\")\n",
        "    total_count = len(string)\n",
        "    gc_percentage = (gc_count / total_count) * 100\n",
        "\n",
        "    return(gc_percentage)\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "def check_illegal_sites(sequence, enzymes):\n",
        "    illegal_sites = 0\n",
        "    for enzyme, site in enzymes.items():\n",
        "        matches = re.finditer(site, sequence)\n",
        "        for match in matches:\n",
        "            illegal_sites += 1\n",
        "\n",
        "    return(illegal_sites)\n",
        "\n",
        "def get_index(text):\n",
        "    periods = []\n",
        "    parentheses = []\n",
        "\n",
        "    for match in re.finditer(r'\\.|[()]', text):\n",
        "        if match.group() == '.':\n",
        "            periods.append(match.start())\n",
        "        elif match.group() == '(' or match.group() == ')':\n",
        "            parentheses.append(match.start())\n",
        "    return periods, parentheses\n",
        "\n",
        "def get_prob(target, matrix):\n",
        "    # target = str(tube_results.complexes[Complex([b, a, c], name='(b+a+c)')].mfe[0][0]).replace(\"+\", \"\")\n",
        "    target = target.replace('+', '')\n",
        "    # matrix = pairs(Complex([b, a, c], name='(b+a+c)'), model=model1).to_array()\n",
        "    diagonal_elements = np.diag(matrix)\n",
        "    non_diagonal_array = matrix - diagonal_elements\n",
        "    prob = []\n",
        "    for i in range(len(target)):\n",
        "        if target[i] == ')' or target[i] == '(':\n",
        "            prob.append(np.max(non_diagonal_array[i]))\n",
        "        elif target[i] == '.':\n",
        "            prob.append(diagonal_elements[i])\n",
        "        else:\n",
        "            continue\n",
        "    return prob\n",
        "\n",
        "def get_probability_onoff(index, data):\n",
        "    prob = []\n",
        "    for i in index:\n",
        "        prob.append(data[i])\n",
        "    return prob\n",
        "\n",
        "def on_off(text, data):\n",
        "    periods, parentheses = get_index(text)\n",
        "    prob_on  = []\n",
        "    prob_off = []\n",
        "    prob_on = get_probability_onoff(periods, data)\n",
        "    prob_off = get_probability_onoff(parentheses, data)\n",
        "    return(prob_on, prob_off)\n",
        "\n",
        "def on_off_level(text, data):\n",
        "    prob_on, prob_off = on_off(text, data)\n",
        "    on_level = sum(prob_on)/len(text)\n",
        "    off_level = sum(prob_off)/len(text)\n",
        "    return(on_level, off_level)\n",
        "\n",
        "def stats(lists):\n",
        "    try:\n",
        "        mean = sum(lists) / len(lists)\n",
        "        squared_differences = [(x - mean)**2 for x in lists]\n",
        "        variance = sum(squared_differences) / len(lists)\n",
        "        standard_deviation = variance**0.5\n",
        "        sum_res = sum(lists)\n",
        "\n",
        "        return(mean, sum_res, standard_deviation)\n",
        "    except ZeroDivisionError:\n",
        "        print(\"Error: Division by zero.\")\n",
        "        return 0, 0, 0\n",
        "\n",
        "def get_analyze(t, df):\n",
        "    seq = str.upper((df.loc[(df['Trial'] == t) & (df['Domain_Strand'] == 'LiRA'), 'Sequence'].values)[0])\n",
        "    mir21 = 'UAGCUUAUCAGACUGAUGUUGA'\n",
        "    mir92a = 'UAUUGCACUUGUCCCGGCCUGU'\n",
        "\n",
        "\n",
        "    # define illegal sites enzymes\n",
        "    '''\n",
        "    Ecori: GAATTC GAAUUC\n",
        "    Xbai: TCTAGA UCUAGA\n",
        "    Spei: ACTAGT ACUAGU\n",
        "    Psti: CTGCAG CUGCAG\n",
        "    noti:GCGGCCGC\n",
        "    '''\n",
        "    enzymes = {\n",
        "      \"EcoRI\": \"GAATTC\",\n",
        "      \"EcoRI2\": \"GAAUUC\",\n",
        "      \"XbaI\": \"TCTAGA\",\n",
        "      \"XbaI2\": \"UCUAGA\",\n",
        "      \"SpeI\": \"ACTAGT\",\n",
        "      \"SpeI2\": \"ACUAGU\",\n",
        "      \"PstI\": \"CTGCAG\",\n",
        "      \"PstI2\": \"CUGCAG\",\n",
        "      \"NotI\": \"GCGGCCGC\"\n",
        "    }\n",
        "    # analysis job\n",
        "\n",
        "    # specify strands\n",
        "    a = Strand(seq, name='a')\n",
        "    b = Strand(mir21, name='b')\n",
        "    c = Strand(mir92a, name='c')\n",
        "\n",
        "    # specify tubes\n",
        "    t1 = Tube(strands={a: 1e-6, b: 1e-6, c: 1e-6}, complexes=SetSpec(max_size=3, include=[[a,b], [a,c], [a,b,c]]), name='t1')\n",
        "    # t2 = Tube(strands={a: 1e-10, b: 1e-9}, complexes=SetSpec(max_size=2), name='t2')\n",
        "\n",
        "    # analyze tubes\n",
        "    model1 = Model()\n",
        "    tube_results = tube_analysis(tubes=[t1], model=model1, compute=['mfe','ensemble_size'])\n",
        "\n",
        "    # Split the ASCII result into lines\n",
        "    lines = str(tube_results).split('\\n')\n",
        "\n",
        "    # Extract the column names\n",
        "    columns = lines[0].split()\n",
        "\n",
        "    # Create an empty list to store the data rows\n",
        "    concen_data = []\n",
        "\n",
        "    # Iterate over the lines starting from the second line\n",
        "    for line in lines[1:]:\n",
        "        # Split the line into individual values\n",
        "        values = line.split()\n",
        "        # Append the values as a row to the data list\n",
        "        concen_data.append(values)\n",
        "\n",
        "    # Iterate through the list and find the index containing 'Concentration'\n",
        "    index = None\n",
        "    for i, sublist in enumerate(concen_data):\n",
        "        if 'Concentration' in sublist:\n",
        "            index = i\n",
        "            break\n",
        "\n",
        "    new_data = concen_data[index+1:]\n",
        "    # Create the dataframe\n",
        "    concen = pd.DataFrame(new_data[1:], columns=new_data[0][:-1], )\n",
        "\n",
        "    #  data get from each sequence\n",
        "    c0 = Complex([a], name='(a)')\n",
        "    c1 = Complex([a, c, b], name='(a+c+b)')\n",
        "    c2 = Complex([a, b, c], name='(a+b+c)')\n",
        "    c3 = Complex([a, b], name='(a+b)')\n",
        "    c4 = Complex([a, c], name='(a+c)')\n",
        "    c5 = Complex([a, a], name='(a+a)')\n",
        "\n",
        "    data = dict ()\n",
        "    data['sequence'] = seq\n",
        "    for c in [c0, c1, c2, c3, c4, c5]:\n",
        "        data[str(c.name) + '_mfe'] =  tube_results.complexes[c].mfe_stack\n",
        "        data[str(c.name) + '_target']  = str(tube_results.complexes[c].mfe[0][0])\n",
        "        data[str(c.name) + '_pfunc'] =  tube_results.complexes[c].pfunc\n",
        "        data[str(c.name) + '_free_energy'] =  tube_results.complexes[c].free_energy\n",
        "        data[str(c.name) + '_ensemble_size'] =  tube_results.complexes[c].ensemble_size\n",
        "        data[str(c.name) + '_mfe_energy'] =  tube_results.complexes[c].mfe_stack\n",
        "        data[str(c.name) + '_mfe_stack_energy'] =  tube_results.complexes[c].mfe[0][2]\n",
        "        data[str(c.name) + '_t1'] = concen.loc[concen['Complex'] == str(c.name), 't1'].values[0]\n",
        "        data[str(c.name) + '_t1_rank'] = concen.index[concen['Complex'] == str(c.name)][0]\n",
        "        data['on_' + str(c.name)] = len(re.findall(r'\\.', str(tube_results.complexes[c].mfe[0][0]))[get_rbs_index(c):get_rbs_index(c)+18])\n",
        "        print(get_rbs_index(c))\n",
        "        data['off_'+ str(c.name)] = len(re.findall(r'[()]', str(tube_results.complexes[c].mfe[0][0]))[get_rbs_index(c):get_rbs_index(c)+18])\n",
        "        data['prob_matrix_'+ str(c.name)] = pairs(c, model=model1).to_array()\n",
        "\n",
        "        data['prob_' + str(c.name)] = get_prob(str(tube_results.complexes[c].mfe[0][0]).replace(\"+\", \"\"), pairs(c, model=model1).to_array())\n",
        "        data['prob_on_' + str(c.name)], data['prob_off_' + str(c.name)] = on_off(str(tube_results.complexes[c].mfe[0][0])[get_rbs_index(c):get_rbs_index(c)+18], data['prob_' + str(c.name)])\n",
        "        data['on_level_' + str(c.name)], data['off_level_' + str(c.name)] = on_off_level(str(tube_results.complexes[c].mfe[0][0])[get_rbs_index(c):get_rbs_index(c)+18], data['prob_' + str(c.name)])\n",
        "        data['on_mean_' + str(c.name)], data['on_sum_' + str(c.name)], data['on_stdev_' + str(c.name)] = stats(data['prob_on_' + str(c.name)])\n",
        "        data['off_mean_' + str(c.name)], data['off_sum_' + str(c.name)], data['off_stdev_' + str(c.name)] = stats(data['prob_off_' + str(c.name)])\n",
        "\n",
        "    data['defect'] = defect(strands=[seq], structure=data['(a)_target'], model=model1)\n",
        "    data['structure_prob'] = structure_probability(strands=[seq], structure=data['(a)_target'], model=model1)\n",
        "    # data['prob_matrix'] = pairs(strands=[seq], model=model1).to_array()\n",
        "    # data['prob_diagonal'] = np.diagonal(pairs(strands=[seq], model=model1).to_array())\n",
        "    data['gc_content'] = calculate_gc_percentage(seq)\n",
        "    data['illegal_count'] = check_illegal_sites(seq, enzymes)\n",
        "    return(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_xyNiZ6GfN7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./table_data_a10996f7-3a7c-49eb-ba3c-bf682effc883.csv')\n",
        "datas = []\n",
        "for i in df['Trial'].unique().tolist():\n",
        "    datas.append(get_analyze(i, df))\n",
        "result = pd.DataFrame(datas)\n",
        "result.head(20)\n",
        "result.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzTSN0oDIm_1"
      },
      "outputs": [],
      "source": [
        "def get_on_off_each_seq(cols_complex, result)\n",
        "  for i in cols_complex:\n",
        "      print(i)\n",
        "      on_off_ratio = []\n",
        "      on_off_minus = []\n",
        "      for j in range(len(result)):\n",
        "          # print(result['on_level_' + str(i)][j])\n",
        "          # print(result['off_level_' + str(i)][j])\n",
        "          ratio = result['on_level_' + str(i)][j] / result['off_level_' + str(i)][j]\n",
        "          minus = result['on_level_' + str(i)][j] - result['off_level_' + str(i)][j]\n",
        "          # print(ratio)\n",
        "          on_off_ratio.append(ratio)\n",
        "          on_off_minus.append(minus)\n",
        "  return(on_off_ratio, on_off_minus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiSpffr7Isn1"
      },
      "outputs": [],
      "source": [
        "def get_metrics(cols_complex, result):\n",
        "  ratio_avg_list = []\n",
        "  minus_avg_list = []\n",
        "  on_level_avg_list = []\n",
        "  off_level_avg_list = []\n",
        "  w_ratio_avg_list = []\n",
        "  w_minus_avg_list = []\n",
        "  w_on_level_avg_list = []\n",
        "  w_off_level_avg_list = []\n",
        "  for j in range(len(result)):\n",
        "      ratio_avg = 0\n",
        "      minus_avg = 0\n",
        "      on_level_avg = 0\n",
        "      off_level_avg = 0\n",
        "      weighted_on_level_avg = 0\n",
        "      weighted_off_level_avg = 0\n",
        "      weighted_minus_avg = 0\n",
        "      weighted_ratio_avg = 0\n",
        "      for i in cols_complex:\n",
        "          # complex regression: ['(a+c+b)', '(a+b+c)', '(a+b)', '(a+c)']\n",
        "          ratio_avg += result['on_off_ratio_' + str(i)][j]\n",
        "          minus_avg += result['on_off_minus_' + str(i)][j]\n",
        "          on_level_avg += result['on_level_' + str(i)][j]\n",
        "          off_level_avg += result['off_level_' + str(i)][j]\n",
        "          weighted_on_level_avg += (1/(result[str(i) + '_t1_rank'][j]+1))*result['on_level_' + str(i)][j]\n",
        "          weighted_off_level_avg += (1/(result[str(i) + '_t1_rank'][j]+1))*result['off_level_' + str(i)][j]\n",
        "          weighted_ratio_avg += (1/(result[str(i) + '_t1_rank'][j]+1))*result['on_off_ratio_' + str(i)][j]\n",
        "          weighted_minus_avg += (1/(result[str(i) + '_t1_rank'][j]+1))*result['on_off_minus_' + str(i)][j]\n",
        "          # print(result['on_off_ratio_' + str(i)][j])\n",
        "      ratio_avg_list.append(ratio_avg/len(cols_complex))\n",
        "      minus_avg_list.append(ratio_avg/len(cols_complex))\n",
        "      on_level_avg_list.append(on_level_avg/len(cols_complex))\n",
        "      off_level_avg_list.append(off_level_avg/len(cols_complex))\n",
        "      #weighted\n",
        "      w_minus_avg_list.append(weighted_ratio_avg/len(cols_complex))\n",
        "      w_ratio_avg_list.append(weighted_ratio_avg/len(cols_complex))\n",
        "      w_on_level_avg_list.append(weighted_on_level_avg/len(cols_complex))\n",
        "      w_off_level_avg_list.append(weighted_off_level_avg/len(cols_complex))\n",
        "      return(ratio_avg_list, minus_avg_list, on_level_avg_list, off_level_avg_list,\n",
        "             w_ratio_avg_list, w_minus_avg_list, w_on_level_avg_list, w_off_level_avg_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rigii08HD0c"
      },
      "outputs": [],
      "source": [
        "def get_complex(df):\n",
        "  cols_complex = []\n",
        "  for i in df.columns[df.columns.str.startswith('on_level_')].tolist()[1:-1]:\n",
        "    cols_complex.append(i.split('on_level_')[1])\n",
        "  print(cols_complex)\n",
        "  return(cols_complex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88_R8ww1KWd5"
      },
      "outputs": [],
      "source": [
        "cols_complex = get_complex(result)\n",
        "result['on_off_ratio_' + str(i)], result['on_off_minus_' + str(i)] = get_on_off_each_seq(cols_complex, result)\n",
        "result['on_off_ratio_avg'], result['on_off_minus_avg'], result['on_level_avg'], result['off_level_avg'], result['weighted_on_off_ratio_avg'], result['weighted_on_off_minus_avg'], result['weighted_on_level_avg'], result['weighted_off_level_avg'] = get_metrics(cols_complex, result)\n",
        "save_data(result, 'nupack_params.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPyDaoCT0jMx"
      },
      "source": [
        "# 2.1-kqs-parameter-gathering-mfe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCSpQdIA0vbP"
      },
      "outputs": [],
      "source": [
        "!pip install ViennaRNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfDKXuyx1GIt"
      },
      "outputs": [],
      "source": [
        "def mfe_segment(data):\n",
        "  list_domain = ['ABS',\n",
        "                  'ABS_',\n",
        "                  'ATS',\n",
        "                  'Complementstart',\n",
        "                  'DBSCom',\n",
        "                  'Loop',\n",
        "                  'RBS',\n",
        "                  'StartCodon',\n",
        "                  '_DBS',\n",
        "                  'loopCom',\n",
        "                  'loopRBS',\n",
        "                  'miR21bottomseal1',\n",
        "                  'miR21bottomseal2',\n",
        "                  'miR21topseal',\n",
        "                  'miR92bottomseal1',\n",
        "                  'miR92bottomseal2',\n",
        "                  'miR92topseal',\n",
        "                  'toeholdmiR92',\n",
        "                  'toeholdmir21']\n",
        "  list_segment = [['ABS', 'Complementstart', 'ABS_', 'Loop', 'ATS', 'loopRBS', 'miR21bottomseal1'],\n",
        "                  ['toeholdmir21', 'miR21topseal', 'miR21bottomseal2', 'miR92bottomseal1', 'toeholdmiR92', 'miR92topseal'],\n",
        "                  ['miR92bottomseal2', 'RBS', 'loopCom', '_DBS', 'StartCodon', 'DBSCom']]\n",
        "  res = dict()\n",
        "  list_name = ['ABS-miR21bottomseal1', 'toeholdmir21-miR92topseal', 'miR92bottomseal2-end']\n",
        "  for j, name in zip(list_segment, list_name):\n",
        "    # get The RNA sequence segment\n",
        "    seq = ''\n",
        "    for i in j:\n",
        "      # print(i)\n",
        "      dom = data.loc[data['Domain_Strand'] == str(i), 'Sequence'].values[0]\n",
        "      seq += dom\n",
        "    seq = seq.lower()\n",
        "    print(seq)\n",
        "    # compute minimum free energy (MFE) and corresponding structure\n",
        "    (ss, mfe) = RNA.fold(seq)\n",
        "    res['mfe_' + name] = mfe\n",
        "  return(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeWS38s608uH"
      },
      "outputs": [],
      "source": [
        "import RNA\n",
        "import pandas as pd\n",
        "url='https://drive.google.com/file/d/1ulrMr39Uy2RaSLEaGBGOVwtSGhN11gPS/view?usp=sharing'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "\n",
        "df = pd.read_csv(dwn_url)\n",
        "datas = []\n",
        "for i in df['Trial'].unique().tolist():\n",
        "    datas.append(mfe_segment(df[df['Trial']==i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7zUaEQbhZRN"
      },
      "source": [
        "#3.0-kqs-modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWHw6BYZhb4z"
      },
      "outputs": [],
      "source": [
        "df1 = get_df('nupack_10_weighted.csv')\n",
        "df2 = get_df('mfe_data_10trial_revisi.csv')\n",
        "df = pd.concat([df1, df2], axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVp006wjJyUX"
      },
      "outputs": [],
      "source": [
        "# get columns that has variation of complexes\n",
        "cols_complex = []\n",
        "for i in df.columns[df.columns.str.startswith('on_level_')].tolist()[1:-1]:\n",
        "  cols_complex.append(i.split('on_level_')[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMbc4tgZJVuC"
      },
      "outputs": [],
      "source": [
        "# get the list of columns to get into regression\n",
        "  _param = ['_mfe',\n",
        "          '_pfunc',\n",
        "          '_free_energy',\n",
        "          '_ensemble_size',\n",
        "          '_mfe_energy',\n",
        "          '_mfe_stack_energy',\n",
        "          '_t1',\n",
        "          '_t1_rank']\n",
        "  param_  = ['on_level_',\n",
        "            'off_level_',\n",
        "            'on_mean_',\n",
        "            'on_sum_',\n",
        "            'on_stdev_',\n",
        "            'off_mean_',\n",
        "            'off_sum_',\n",
        "            'off_stdev_']\n",
        "  param = ['mfe_ABS-miR21bottomseal1', 'mfe_toeholdmir21-miR92topseal',\n",
        "          'mfe_miR92bottomseal2-end',\n",
        "          'gc_content', 'structure_prob', 'defect']\n",
        "import numpy as np\n",
        "def prepro(df, mode = 'infinity'):\n",
        "  # change datatype to float\n",
        "  df['(a)_pfunc'] = df['(a)_pfunc'].astype(float)\n",
        "  df['(a)_ensemble_size'] = df['(a)_ensemble_size'].astype(float)\n",
        "  df['(a+c+b)_ensemble_size'] = df['(a+c+b)_ensemble_size'].astype(float)\n",
        "  df['(a+b+c)_ensemble_size'] = df['(a+b+c)_ensemble_size'].astype(float)\n",
        "  df['(a+b)_ensemble_size'] = df['(a+b)_ensemble_size'].astype(float)\n",
        "  df['(a+c)_ensemble_size'] = df['(a+c)_ensemble_size'].astype(float)\n",
        "  df['(a+a)_ensemble_size'] = df['(a+a)_ensemble_size'].astype(float)\n",
        "  df_non_inf = pd.DataFrame()\n",
        "  if mode == 'infinity':\n",
        "    # Check which rows contain infinity values\n",
        "    rows_with_inf = df.isin([np.inf]).any(axis=1)\n",
        "\n",
        "    # Drop rows with infinity values\n",
        "    df_non_inf = df.drop(index = pd.Series(rows_with_inf)[pd.Series(rows_with_inf)].index[0])\n",
        "  return(df, df_non_inf)\n",
        "\n",
        "def get_param(df, _param, cols_complex):\n",
        "\n",
        "  params_all = []\n",
        "  for i in cols_complex:\n",
        "    for j in _param:\n",
        "      params_all.append(str(i+j))\n",
        "    # for k in param_:\n",
        "    #   params_all.append(str(k+i))\n",
        "  params_all.extend(param)\n",
        "  return(params_all)\n",
        "print(len(cols_complex)*(len(_param))+len(param))\n",
        "len(params_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYA2XQB5K1hq"
      },
      "outputs": [],
      "source": [
        "# modelling\n",
        "def get_mse_rmse(y_test, y_pred):\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  rmse = np.sqrt(mse)\n",
        "  return mse, rmse\n",
        "\n",
        "def linreg(X, y):\n",
        "  sc_X = StandardScaler()\n",
        "  X = sc_X.fit_transform(X)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Build linear regression model\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "  # Make predictions on testing set\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  mse, rmse = get_mse_rmse(y_test, y_pred)\n",
        "\n",
        "  print('MSE:', mse)\n",
        "  print('RMSE:', rmse)\n",
        "  return(model)\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = df_non_inf[params_all]\n",
        "y = df_non_inf['on_off_ratio_avg']\n",
        "model = linreg(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etech-saLnC5"
      },
      "outputs": [],
      "source": [
        "def display_metrics(sf, sc):\n",
        "  display(pd.DataFrame({\n",
        "      'Features': sf,\n",
        "      'Coefficients': sc,\n",
        "      'Absolute Coefficients': np.abs(sc)\n",
        "  }))\n",
        "\n",
        "def metrics(model, params_all):\n",
        "  # Get the coefficients of the linear regression model\n",
        "  coefficients = model.coef_\n",
        "\n",
        "  # Sort the coefficients in descending order\n",
        "  sorted_indices = np.argsort(coefficients)[::-1].tolist()\n",
        "  print(sorted_indices)\n",
        "  sorted_coefficients = coefficients[sorted_indices]\n",
        "  sorted_features = sorted(params_all, key=lambda x: sorted_indices.index(params_all.index(x)))\n",
        "\n",
        "  # Print or visualize the feature importances\n",
        "  for feature, importance in zip(sorted_features, sorted_coefficients):\n",
        "      print(f\"{feature}: {importance}\")\n",
        "\n",
        "  # Create a bar plot of feature importances\n",
        "  plt.bar(range(len(sorted_features)), sorted_coefficients)\n",
        "  plt.xticks(range(len(sorted_features)), sorted_features, rotation='vertical')\n",
        "  plt.xlabel('Features')\n",
        "  plt.ylabel('Coefficient')\n",
        "  plt.title('Feature Coefficients')\n",
        "  plt.show()\n",
        "  return(zip(sorted_features, sorted_coefficients))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO6RWMjXhcfV"
      },
      "source": [
        "#4.0-kqs-EDA"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
